{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3d7fd9",
   "metadata": {},
   "source": [
    "## Logits, Softmax, Label Smoothing with Fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924ace3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "MixUp, Label Smoothing ...\n",
    "\n",
    "- [Lesson 12 (2019) - Advanced training techniques; ULMFiT from scratch](https://youtu.be/vnOpEwmtFJ8)\n",
    "\n",
    "- [class MixUp](https://docs.fast.ai/callback.mixup.html#MixUp)\n",
    "\n",
    "- [Revisiting ResNets: Improved Training and Scaling Strategies](https://wandb.ai/wandb_fc/pytorch-image-models/reports/Revisiting-ResNets-Improved-Training-and-Scaling-Strategies--Vmlldzo2NDE3NTM?s=09)\n",
    "\n",
    "![image|476x351](upload://f3TJwptFmeQEoe6MjUUfhEEhcny.png)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0a559",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "**fastai course:**\n",
    "- [Practical Deep Learning for Coders (a UQ collaboration with fast.ai)](https://itee.uq.edu.au/event/2022/practical-deep-learning-coders-uq-fastai)  \n",
    "\n",
    "**Jeremy's Notebook Series:**\n",
    "- [First Steps: Road to the Top, Part 1](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1)\n",
    "- [Small models: Road to the Top, Part 2](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2)\n",
    "- [Scaling Up: Road to the Top, Part 3](https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3)\n",
    "- [Multi-target: Road to the Top, Part 4](https://www.kaggle.com/code/jhoward/multi-target-road-to-the-top-part-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669b70d",
   "metadata": {},
   "source": [
    "## Installing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "517b2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastkaggle allows you to work locally and then submit the results and notebook to Kaggle\n",
    "\n",
    "try: import fastkaggle\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "ebdf9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition = 'paddy-disease-classification'\n",
    "path = setup_comp(competition, install='fastai \"timm>=0.6.2.dev0\"')\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from scipy.special import softmax, log_softmax\n",
    "from functools import partial\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1bee84",
   "metadata": {},
   "source": [
    "## Setting data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3f9e401e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>variety</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100330.jpg</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100365.jpg</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100382.jpg</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100632.jpg</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101918.jpg</td>\n",
       "      <td>bacterial_leaf_blight</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                  label variety  age\n",
       "0  100330.jpg  bacterial_leaf_blight   ADT45   45\n",
       "1  100365.jpg  bacterial_leaf_blight   ADT45   45\n",
       "2  100382.jpg  bacterial_leaf_blight   ADT45   45\n",
       "3  100632.jpg  bacterial_leaf_blight   ADT45   45\n",
       "4  101918.jpg  bacterial_leaf_blight   ADT45   45"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train images\n",
    "train_path = path / 'train_images'\n",
    "train_files = get_image_files(train_path)\n",
    "\n",
    "# test images\n",
    "test_path = path/'test_images'\n",
    "test_files = get_image_files(test_path).sorted()\n",
    "\n",
    "# sample submission\n",
    "sample_submission = pd.read_csv(path/'sample_submission.csv')\n",
    "\n",
    "# train labels\n",
    "train_df = pd.read_csv(path / 'train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c8d58",
   "metadata": {},
   "source": [
    "## Dataloaders for fastai training\n",
    "You can create the dataloader in any of these two ways:\n",
    "1. From a `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6861a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=RandomSplitter(0.2, seed=42),\n",
    "    item_tfms=Resize(480, method='squish'),\n",
    "    batch_tfms=aug_transforms(size=224, min_scale=0.75)\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8977e",
   "metadata": {},
   "source": [
    "## Create a learner and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9fddb",
   "metadata": {},
   "source": [
    "### Custom Loss and Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "24d6116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(inp, disease): \n",
    "    return F.cross_entropy(inp, disease, label_smoothing=label_smoothing)\n",
    "\n",
    "def custom_softmax(x, base=math.e):\n",
    "    \"\"\"If base=2, then the softmax becomes \"SoftmaxBase\" (?)\n",
    "    computed as [2**xi / SUM(2**xi)] instead of [e**xi / SUM(e**xi)]\n",
    "    \"\"\"\n",
    "    # Since `base` can be rewritten as `e**(ln(base))`\n",
    "    # So `base**xi = (e**(ln(base)))**xi = e**(xi*ln(base))`\n",
    "    return F.softmax(x * math.log(base), dim=-1)\n",
    "\n",
    "def no_activation(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8ca0757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=error_rate).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98147c",
   "metadata": {},
   "source": [
    "And that's it, 16 epochs to get the best baseline for the price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67f25c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.736589</td>\n",
       "      <td>1.059424</td>\n",
       "      <td>0.336377</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.668114</td>\n",
       "      <td>0.402552</td>\n",
       "      <td>0.121096</td>\n",
       "      <td>01:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(1, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555adf8",
   "metadata": {},
   "source": [
    "### Predictions and Test Time Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288ba08",
   "metadata": {},
   "source": [
    "Lets compare the error rate -on the validation set- that are obtained with the normal prediction function and with the predictions we can get applying a technique called Test Time Augmentation (TTA). As you'll see, TTA is easy with fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520df898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorBase(0.1211)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions on validation set\n",
    "probs, target = learn.get_preds(dl=dls.valid)\n",
    "error_rate(probs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe631d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorBase(0.1124)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get TTA predictions on validation set\n",
    "probs, target = learn.tta(dl=dls.valid)\n",
    "error_rate(probs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20ec9bd",
   "metadata": {},
   "source": [
    "So you can see a boost with TTA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61985680",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "30d4b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(inp, disease): \n",
    "    return F.cross_entropy(inp, disease, label_smoothing=label_smoothing)\n",
    "\n",
    "def custom_softmix(x, exp=math.e):\n",
    "    return F.softmax(x * math.log(exp), dim=-1)\n",
    "\n",
    "def no_activation(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99bf546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2081, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f813b",
   "metadata": {},
   "source": [
    "- As we can see, `probs` contains 2,081 results (number of validation photos), each with 10 probabilities for each of the ten possible diseases.\n",
    "- The sum of those 10 values adds to 100% in each photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5965d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorBase(100.), TensorBase(100.), TensorBase(100.), TensorBase(100.0000)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sum(row)*100 for row in probs[0:4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd2ade",
   "metadata": {},
   "source": [
    "- But the raw output of neural networks (called logits) is not a probability. Is a serie of 10 numbers that are normalized to make probabilities out of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e1149",
   "metadata": {},
   "source": [
    "#### Para obtener logits\n",
    "- `learn.loss_func = custom_loss` \n",
    "Antes de lam- Llamar a `get_preds` o `tta` asignar `custom_loss` a `loss_func`\n",
    "\n",
    "- `learn.get_preds()`\n",
    "Pasarle el parámetro `act=no_activation` para que no use Softmax como \"normalizador. Pero no puede pasarse a `tta`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26bdd1",
   "metadata": {},
   "source": [
    "### Softmax Excel\n",
    "- Jeremy video\n",
    "- Excel Repository\n",
    "- Google Sheet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cb7c6144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8852,  2.5975,  0.5917, -2.0689, -4.5687],\n",
       "        [-2.8852,  1.5975, -0.5917,  2.0689, -4.5687]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits\n",
    "x = torch.tensor(\n",
    "    [[-4.88522478044709, 2.59747282063147, 0.59166497570264, -2.06894452227226, -4.56867917386799],\n",
    "     [-2.88522478044709, 1.59747282063147, -0.59166497570264, 2.06894452227226, -4.56867917386799]]\n",
    ")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0c74e55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([1,3])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "51b1192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.5574e-03, 1.3430e+01, 1.8070e+00, 1.2632e-01, 1.0372e-02],\n",
       "        [5.5842e-02, 4.9405e+00, 5.5341e-01, 7.9165e+00, 1.0372e-02]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e**xi\n",
    "expxi = x.exp()\n",
    "expxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ae0881e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.3810, 13.4766])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum by row [sum([e**xi])]\n",
    "sum_expxi = expxi.sum(axis=1)\n",
    "sum_expxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0d32e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9135e-04, 8.7314e-01, 1.1748e-01, 8.2127e-03, 6.7432e-04],\n",
       "        [4.1436e-03, 3.6660e-01, 4.1064e-02, 5.8742e-01, 7.6960e-04]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmaxxi = expxi.transpose(0,1)*(1/sum_expxi)\n",
    "softmaxxi = softmaxxi.transpose(0,1)\n",
    "softmaxxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "de54ad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.6184, -0.1357, -2.1415, -4.8021, -7.3018],\n",
       "        [-5.4862, -1.0035, -3.1926, -0.5320, -7.1696]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsoftmaxxi = softmaxxi.log()\n",
    "logsoftmaxxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a4448581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe = np.zeros((len(target), len(x[0])))\n",
    "y_ohe[np.arange(len(target)), target] = 1\n",
    "y_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d26ea999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1357, -0.5320], dtype=torch.float64)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossi = (logsoftmaxxi * y_ohe).sum(dim=-1)\n",
    "lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "be76c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3338, dtype=torch.float64)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_loss = (logsoftmaxxi * y_ohe).sum(dim=-1).mean()\n",
    "mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6984f",
   "metadata": {},
   "source": [
    "#### scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3f9cb883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9135e-04, 8.7314e-01, 1.1748e-01, 8.2127e-03, 6.7432e-04],\n",
       "        [4.1436e-03, 3.6660e-01, 4.1064e-02, 5.8742e-01, 7.6960e-04]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "68e2ac2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.6183577 , -0.13565996, -2.1414678 , -4.8020773 , -7.301812  ],\n",
       "       [-5.4861803 , -1.0034829 , -3.1926208 , -0.5320113 , -7.169635  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8a482de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.6184, -0.1357, -2.1415, -4.8021, -7.3018],\n",
       "        [-5.4862, -1.0035, -3.1926, -0.5320, -7.1696]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x, axis=1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cd129",
   "metadata": {},
   "source": [
    "#### pythorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6f026e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9135e-04, 8.7314e-01, 1.1748e-01, 8.2127e-03, 6.7432e-04],\n",
       "        [4.1436e-03, 3.6660e-01, 4.1064e-02, 5.8742e-01, 7.6960e-04]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ffae6bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.6184, -0.1357, -2.1415, -4.8021, -7.3018],\n",
       "        [-5.4862, -1.0035, -3.1926, -0.5320, -7.1696]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "093bba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3338)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(F.log_softmax(x, dim=-1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "01a44924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3338)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0d612bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(target, len(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92229337",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "46272b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3262,  0.4573, -2.7969,  0.5376,  0.3630,  0.8218,  1.6855, -3.5312,\n",
       "         -1.7969, -1.6748],\n",
       "        [-1.4180,  1.0996, -2.0195,  3.6406,  0.5249,  1.2031,  1.6191, -0.6860,\n",
       "         -2.4746, -1.8027]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "  [3.326171875,0.457275391,-2.796875000,0.537597656,0.363037109,0.821777344,1.685546875,-3.531250000,-1.796875000,-1.674804688],\n",
    "  [-1.417968750,1.099609375,-2.019531250,3.640625000,0.524902344,1.203125000,1.619140625,-0.686035156,-2.474609375,-1.802734375]\n",
    "])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ea9a18f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([0,3])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2eb2b7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3794, 0.3167])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(x, target, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a6798a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3480)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_loss = F.cross_entropy(x, target)\n",
    "mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ca15d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7381, 0.6839])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Label Smoothing\n",
    "F.cross_entropy(x, target, reduction='none', label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9ba1b18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7110)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(x, target, label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d06953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "7b7bacf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8425e-01, 3.8839e-02, 1.4997e-03, 4.2088e-02, 3.5346e-02, 5.5921e-02,\n",
       "         1.3265e-01, 7.1958e-04, 4.0767e-03, 4.6060e-03],\n",
       "        [4.6297e-03, 5.7401e-02, 2.5369e-03, 7.2857e-01, 3.2309e-02, 6.3662e-02,\n",
       "         9.6505e-02, 9.6256e-03, 1.6094e-03, 3.1510e-03]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ec7b9c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8425e-01, 3.8839e-02, 1.4997e-03, 4.2088e-02, 3.5346e-02, 5.5921e-02,\n",
       "         1.3265e-01, 7.1958e-04, 4.0767e-03, 4.6060e-03],\n",
       "        [4.6297e-03, 5.7401e-02, 2.5369e-03, 7.2857e-01, 3.2309e-02, 6.3662e-02,\n",
       "         9.6505e-02, 9.6256e-03, 1.6094e-03, 3.1510e-03]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_softmix(x, exp=math.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e400b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_sofmax = partial(custom_softmix, exp=math.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ce45bee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8425e-01, 3.8839e-02, 1.4997e-03, 4.2088e-02, 3.5346e-02, 5.5921e-02,\n",
       "         1.3265e-01, 7.1958e-04, 4.0767e-03, 4.6060e-03],\n",
       "        [4.6297e-03, 5.7401e-02, 2.5369e-03, 7.2857e-01, 3.2309e-02, 6.3662e-02,\n",
       "         9.6505e-02, 9.6256e-03, 1.6094e-03, 3.1510e-03]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_sofmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "81b7d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_sofmax2 = partial(custom_softmix, exp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "de6c7b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5026, 0.0688, 0.0072, 0.0727, 0.0644, 0.0886, 0.1612, 0.0043, 0.0144,\n",
       "         0.0157],\n",
       "        [0.0162, 0.0926, 0.0107, 0.5390, 0.0622, 0.0995, 0.1328, 0.0269, 0.0078,\n",
       "         0.0124]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_sofmax2(x) # 2**xi / sum(2**xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9e91db5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_sofmax2(x).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "04515c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5026, 0.0688, 0.0072, 0.0727, 0.0644, 0.0886, 0.1612, 0.0043, 0.0144,\n",
       "         0.0157],\n",
       "        [0.0162, 0.0926, 0.0107, 0.5390, 0.0622, 0.0995, 0.1328, 0.0269, 0.0078,\n",
       "         0.0124]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x * math.log(2), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac8a73",
   "metadata": {},
   "source": [
    "### Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f8ded9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TTA predictions from test images\n",
    "probs, _ = learn.tta(dl=dls.test_dl(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b24511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index with the greater probability\n",
    "preds = probs.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818b6d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3469) ['hispa','normal','blast','blast','blast','brown_spot','dead_heart','brown_spot','hispa','normal'...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.vocab[preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbebf0",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2759a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.label = dls.vocab[preds]\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec89c09",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c783be",
   "metadata": {},
   "source": [
    "* I found this model being a good baseline, with a good accuracy for its speed and cost.\n",
    "* You can try different epochs, learning rates, or even a different seed and see what happens when submitting the results.\n",
    "* Then you can apply some of the techniques that Jeremy applied in his series.\n",
    "* And keep trying.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7706778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel version 1 successfully pushed.  Please check progress at https://www.kaggle.com/code/fmussari/fast-resnet34-with-fastai\n"
     ]
    }
   ],
   "source": [
    "# Pushing the notebook from my home PC to Kaggle\n",
    "\n",
    "if not iskaggle:\n",
    "    push_notebook(\n",
    "        'fmussari', \n",
    "        'fast-resnet34-with-fastai',\n",
    "        title='Fast Resnet34 with Fastai',\n",
    "        file='2022-07. Fast and Agile Resnet34 with Fastai.ipynb',\n",
    "        competition=competition, \n",
    "        private=True, \n",
    "        gpu=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5533b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
